{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af350188-b4d1-4d52-ab17-bd0ed40c9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from matplotlib import pyplot as plt\n",
    "    from prettytable import PrettyTable\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError as err:\n",
    "    print(f\"[-] Could not find module: {err}\")\n",
    "    print(f\"[-] Try pip install {err} to install the package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8deb1b61-aec8-47d7-9d6e-ecfcb6e72804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_types(dataframe_object):\n",
    "    \"\"\"\n",
    "    returns the data type each column by looping through each column's\n",
    "    first element and checking their data type.\n",
    "    This is required because the inbuilt function info (deprecated now)\n",
    "    is not able to distinguish between the complex data types\n",
    "\n",
    "    Parameters:\n",
    "    dataframe_object: A dataframe object i.e. something which was created using\n",
    "    pandas.read_csv, pandas.read_excel etc.\n",
    "    \"\"\"\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Column\", \"Non-Null Count\", \"Dtype\"]\n",
    "\n",
    "    for column in dataframe_object.columns:\n",
    "        non_null_count = int(len(dataframe_object) -\n",
    "                             dataframe_object[column].isna().sum())\n",
    "        data_type = type(dataframe_object[column].iloc[0])\n",
    "        if data_type == None:\n",
    "            i = 0\n",
    "            while i < len(dataframe_object):\n",
    "                data_type = type(dataframe_object[column].iloc[i])\n",
    "                if data_type != None:\n",
    "                    break\n",
    "                i += 1\n",
    "        table.add_row([column, non_null_count, data_type])\n",
    "\n",
    "    print(table)\n",
    "\n",
    "\n",
    "def lat_lon_str_parser(column, data):\n",
    "    \"\"\"\n",
    "    The data contained in the latitude and longitude columns are in array which \n",
    "    gets saved as string. \n",
    "    This function parses to string and finds the most frequent values within the\n",
    "    array to return a single value of latitude or longitude. This can be used\n",
    "    to replace the string of array in the latitude or longitude by a single value.\n",
    "    \n",
    "    Example of data: \"['0.000000', '0.000000', '0.000000', '0.000000']\"\n",
    "    Parameters\n",
    "    column: The column of the dataframe which needs to be parsed\n",
    "    \"\"\"\n",
    "    lat_list = []\n",
    "    try:\n",
    "        if type(data[column].iloc[0]) != str:\n",
    "            return data[column]\n",
    "        \n",
    "        for row in range(len(data)):\n",
    "            try:\n",
    "                item = data[column].iloc[row]\n",
    "                if len(item) < 20:\n",
    "                    lat_list.append(float(item))\n",
    "                else:\n",
    "                    values = item.split(\",\")\n",
    "                    res = float(max(set(values), key=values.count).split(\"'\")[1])\n",
    "                    lat_list.append(res)\n",
    "            except AttributeError:\n",
    "                lat_list.append(np.nan)\n",
    "                \n",
    "    except TypeError as err:\n",
    "        print(f\"[-] Type error: {err}\")\n",
    "        return []\n",
    "    \n",
    "    return lat_list\n",
    "\n",
    "\n",
    "\n",
    "def sog_cog_to_num(column, data):\n",
    "    \"\"\"\n",
    "    Some of the data collected from the IMU sensors are sent as string of array.\n",
    "    We need to parse the string and extract the array with numerical values.\n",
    "    \n",
    "    Example of data: \"['0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\"\n",
    "    Parameters\n",
    "    column: The column of the dataframe which needs to be parsed.\n",
    "    \"\"\"\n",
    "    return_list = []\n",
    "    for row in range(len(data)):\n",
    "        row_list = []\n",
    "        for i in range(1000):\n",
    "            try:\n",
    "                num = float(data[column].iloc[row].split(\"[\")[1].split(\"]\")[0].split(\",\")[i].split(\"'\")[1])\n",
    "                row_list.append(num)\n",
    "            except AttributeError:\n",
    "                row_list.append(np.nan)\n",
    "\n",
    "        return_list.append(row_list)\n",
    "\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def label_parser(column, data):\n",
    "    \"\"\"\n",
    "    The label of data collected is in string format. This function parses\n",
    "    the string into individual string values. The output is an array of string \n",
    "    values which tells the road condition.\n",
    "\n",
    "    Example of data: \"['Roughroad', 'Roughroad', 'Roughroad', 'Roughroad']\"\n",
    "    Parameters\n",
    "    column: The column of the dataframe which needs to be parsed.\n",
    "    \"\"\"\n",
    "    return_list = []\n",
    "    for row in range(len(data)):\n",
    "        row_list = []\n",
    "        for i in range(1000):\n",
    "            try:\n",
    "                value = data[column][row].split(\"[\")[1].split(\"]\")[0].split(\",\")[i].split(\"'\")[1]\n",
    "                row_list.append(value)\n",
    "            except AttributeError:\n",
    "                row_list.append(np.nan)\n",
    "\n",
    "        return_list.append(row_list)\n",
    "\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def str_to_num_parser(column, data):\n",
    "    \"\"\"\n",
    "    Parses the data sent as string of array.\n",
    "\n",
    "    Example of data: '[-3696, -1972, 4984, -3248]'\n",
    "\n",
    "    Parameters\n",
    "    column: column of data which needs to be parsed.\n",
    "    \"\"\"\n",
    "    return_list = []\n",
    "    for row in range(len(data)):\n",
    "        value_list = data[column].iloc[row].split(\n",
    "            \"[\")[1].split(\"]\")[0].split(\",\")\n",
    "        row_list = [float(value) for value in value_list]\n",
    "        return_list.append(row_list)\n",
    "\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def pre_processor(df,\n",
    "                  str_arrays=['SogAcc', 'CogAcc','AcX', 'AcY',\n",
    "                              'AcZ', 'GcX', 'GcY', 'GcZ', 'Tmp',\n",
    "                              'Time', 'B', 'A'],\n",
    "                  label_array = ['Label'],\n",
    "                  lat_lon=[],\n",
    "                  cog_sog=[],\n",
    "                  export=False,\n",
    "                  export_name=None):\n",
    "    \"\"\"\n",
    "    This function takes in the dataframe which needs to be processed along with list of columns \n",
    "    which need pre-processing. Different columns can have different pre-processing requirements \n",
    "    and based on the history of data seen, the code has functionality to process them.\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    df: IMU data's dataframe which needs to be  processed.\n",
    "    lat_lon: expects a list of columns which need specific pre-processing. Default is empty list\n",
    "            but for specific datasets it can be set as the example below.\n",
    "    cog_sog: expects a list of columns which need specific pre-processing. Default is empty list\n",
    "            but for specific datasets it can be set as the example below.\n",
    "    str_arrays: expects a list of columns which needs to be converted to array of float values. \n",
    "            The original data should be a simple string of array. In most cases the default values\n",
    "            should hold good.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    pre_processor(df,\n",
    "                  lat_lon=[\"LonAcc\", \"LatAcc\"],\n",
    "                  cog_sog=[\"CogAcc\", \"SogAcc\"],\n",
    "                  str_arrays =['SogAcc',\n",
    "                                 'CogAcc', 'AcX', 'AcY', 'AcZ', 'GcX', 'GcY', 'GcZ', 'Tmp', 'Time', 'B',\n",
    "                                 'A'],\n",
    "                  export=False,\n",
    "                  export_name=None):\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    cols_to_drop = [\"_id\"]\n",
    "    for column in data.columns:\n",
    "        data_points = (data[column].isna().sum()/len(data))\n",
    "        if data_points > 0.50:\n",
    "            cols_to_drop.append(column)\n",
    "    data.drop(columns=cols_to_drop, axis=1, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    try:\n",
    "        for col in lat_lon:\n",
    "            print(col)\n",
    "            data[col] = lat_lon_str_parser(col, data=data)\n",
    "        \n",
    "        for col in label_array:\n",
    "            data[col] = label_parser(col, data=data)\n",
    "            \n",
    "        for col in cog_sog:\n",
    "            print(col)\n",
    "            data[col] = sog_cog_to_num(col, data=data)\n",
    "\n",
    "        for col in str_arrays:\n",
    "            print(col)\n",
    "            data[col] = str_to_num_parser(col, data=data)\n",
    "        \n",
    "        if export:\n",
    "            if export_name == None:\n",
    "                export_name = \"unnamed\"\n",
    "            data.to_csv(f\"{export_name}.csv\", index=False)\n",
    "            print(f\"[+] Exported {export_name}\")\n",
    "\n",
    "    except KeyError as err:\n",
    "        print(f\"[-] Could not find key: {err}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6350c228-95ed-42b2-8844-174f020b8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/abhijeet/Ranjan/Data/AccelerometerData/UnProcessedData/M5accloc11th_May_12_43_13_20_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf2e7cb-8b44-487b-8a86-7097d4b0fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e9bca7-f826-4846-af6b-b199701a8a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------------+\n",
      "|  Column  | Non-Null Count |          Dtype          |\n",
      "+----------+----------------+-------------------------+\n",
      "|   _id    |      201       |      <class 'str'>      |\n",
      "| srvtime  |      201       | <class 'numpy.float64'> |\n",
      "|   P_Id   |      201       |  <class 'numpy.int64'>  |\n",
      "|   name   |      201       |      <class 'str'>      |\n",
      "|  LatAcc  |      201       | <class 'numpy.float64'> |\n",
      "|  LonAcc  |      201       | <class 'numpy.float64'> |\n",
      "|  Label   |      201       |      <class 'str'>      |\n",
      "|  SogAcc  |      201       |      <class 'str'>      |\n",
      "|  CogAcc  |      201       |      <class 'str'>      |\n",
      "|   AcX    |      201       |      <class 'str'>      |\n",
      "|   AcY    |      201       |      <class 'str'>      |\n",
      "|   AcZ    |      201       |      <class 'str'>      |\n",
      "|   GcX    |      201       |      <class 'str'>      |\n",
      "|   GcY    |      201       |      <class 'str'>      |\n",
      "|   GcZ    |      201       |      <class 'str'>      |\n",
      "|   Tmp    |      201       |      <class 'str'>      |\n",
      "|   Time   |      201       |      <class 'str'>      |\n",
      "|    B     |      201       |      <class 'str'>      |\n",
      "|    A     |      201       |      <class 'str'>      |\n",
      "| End_Time |      201       |  <class 'numpy.int64'>  |\n",
      "+----------+----------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "get_data_types(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85fd8897-317c-4046-bd47-0552019eae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SogAcc\n",
      "CogAcc\n",
      "AcX\n",
      "AcY\n",
      "AcZ\n",
      "GcX\n",
      "GcY\n",
      "GcZ\n",
      "Tmp\n",
      "Time\n",
      "B\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "df = pre_processor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e311db-e103-4eac-92a0-c3c07fe4d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------------+\n",
      "|  Column  | Non-Null Count |          Dtype          |\n",
      "+----------+----------------+-------------------------+\n",
      "| srvtime  |      201       | <class 'numpy.float64'> |\n",
      "|   P_Id   |      201       |  <class 'numpy.int64'>  |\n",
      "|   name   |      201       |      <class 'str'>      |\n",
      "|  LatAcc  |      201       | <class 'numpy.float64'> |\n",
      "|  LonAcc  |      201       | <class 'numpy.float64'> |\n",
      "|  Label   |      201       |      <class 'list'>     |\n",
      "|  SogAcc  |      201       |      <class 'list'>     |\n",
      "|  CogAcc  |      201       |      <class 'list'>     |\n",
      "|   AcX    |      201       |      <class 'list'>     |\n",
      "|   AcY    |      201       |      <class 'list'>     |\n",
      "|   AcZ    |      201       |      <class 'list'>     |\n",
      "|   GcX    |      201       |      <class 'list'>     |\n",
      "|   GcY    |      201       |      <class 'list'>     |\n",
      "|   GcZ    |      201       |      <class 'list'>     |\n",
      "|   Tmp    |      201       |      <class 'list'>     |\n",
      "|   Time   |      201       |      <class 'list'>     |\n",
      "|    B     |      201       |      <class 'list'>     |\n",
      "|    A     |      201       |      <class 'list'>     |\n",
      "| End_Time |      201       |  <class 'numpy.int64'>  |\n",
      "+----------+----------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "get_data_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f0a296-ad74-4c91-b6ef-0ed21a98273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_11th_may_run_1_imu_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa8f1c1-fff5-4a29-ab1d-b29d22f13a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abhijeet/Ranjan/Coding/IMU-Preprocessing/acc_data_pre-processor\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be399e35-1227-4c3a-ab6e-a1793e8c3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" /home/abhijeet/Ranjan/Data/AccelerometerData/ProcessedData\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
